{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Wi-SensiNet: Through-Wall Human Activity\\nRecognition Based on WiFi Sensing\\nFu Xiaoyi\\xa0\\nSouthwest University\\nWang Chenlu\\xa0\\nSouthwest University\\nLi Shenglin\\xa0 \\n \\nSouthwest University\\nResearch Article\\nKeywords:  Human activity recognition, Deep learning, WiFi se nsing, Through wall,Channel state\\ninformation\\nPosted Date:  March 19th, 2024\\nDOI:  https://doi.org/10.21203/rs.3.rs-4106293/v1\\nLicense:  \\uf25e \\uf4e7 This work is licensed under a Creative Commons Att ribution 4.0 International License. \\xa0\\nRead Full License\\nAdditional Declarations:  No competing interests reported.', metadata={'source': 'sample.pdf', 'page': 0}),\n",
       " Document(page_content='Wi-SensiNet: Through-Wall Human Activity\\nRecognition Based on WiFi Sensing\\nFu Xiaoyi1, Wang Chenlu1, Li Shenglin1*\\n1*College of Artiﬁcial Intelligence, Southwest University, Chongqing,\\n400715, China.\\n*Corresponding author(s). E-mail(s): lishenglin@swu.edu.cn ;\\nContributing authors: swufuxiaoyi@163.com ;\\nAbstract\\nWith the advancement of Wi-Fi sensing technology, its signi ﬁcant beneﬁts in\\nconvenient operation and privacy protection have become appare nt, particularly\\nin ﬁelds like smart homes, medical monitoring, and security surv eillance, where\\nthe application prospects of Human Activity Recognition (HA R) technology are\\nincreasingly broad. This study focuses on a novel approach to HAR using Wi-Fi\\nChannel State Information (CSI), especially under complex co nditions such as\\nNon-Line of Sight (NLoS) paths and through-wall transmission s. Traditionally,\\nmost research has concentrated on Line of Sight (LoS) path HAR, s ensitive to\\nenvironmental changes, while the NLoS path signals, especia lly through-wall sig-\\nnals, present unpredictability due to weak reﬂections caused b y walls. Addressing\\nthis issue, we propose Wi-SensiNet, an innovative deep learni ng-based method\\nthat combines the spatial feature extraction capabilities of C onvolutional Neural\\nNetworks (CNN) with the temporal sequence processing power of B idirectional\\nLong Short-Term Memory networks (BiLSTM). This method also inco rporates\\nan attention mechanism to enhance the accuracy of human activ ity recogni-\\ntion in complex environments. Wi-SensiNet is specially desi gned for through-wall\\nsettings, eﬀectively handling the complexity of CSI data, a nd achieving accu-\\nrate through-wall human activity detection. In our experiment s, we collected\\na through-wall CSI dataset comprising seven common activitie s, including run-\\nning, sitting, standing, squatting, falling, punching, and walking, and veriﬁed\\nWi-SensiNet’s average accuracy exceeded 99% on the original te st set. These\\nresults not only demonstrate the model’s robustness and high acc uracy in han-\\ndling HAR tasks in complex environments but also highlight th e potential of\\nCNN and BiLSTM working in tandem to enhance performance.\\nKeywords: Human activity recognition, Deep learning, WiFi sensing, Th rough\\nwall,Channel state information\\n1', metadata={'source': 'sample.pdf', 'page': 1}),\n",
       " Document(page_content='1 Introduction\\nIn recent years, Human Activity Recognition (HAR) has increasingly found ap pli-\\ncations in ﬁelds such as smart homes, medical monitoring, and security s urveil-\\nlance.Particularly with the proliferation of smart devices and the adv ancement of\\nInternet of Things (IoT) technologies, Wi-Fi sensing technology has be en increasingly\\napplied, harnessing a detectable feature within Wi-Fi signals kno wn as Channel State\\nInformation (CSI).This type of data can intricately illustrate how w ireless signals\\nare transmitted between sending and receiving devices, where m ovement of a person\\nwithin the Wi-Fi signal propagation path induces changes in the signal’s p hase and\\namplitude.These alterations are reﬂected in the CSI, a characteris tic of Wi-Fi sig-\\nnals, oﬀering detailed insights into the signal propagation path, transmi ssion time,\\nand attenuation.Consequently, by analyzing the variations in CSI data, on e can infer\\nchanges in human movement and positioning.Compared to traditional metho ds reliant\\non visual or wearable sensors, this approach oﬀers a more covert and non-lin e-of-\\nsight dependent solution.Wi-Fi-based Human Activity Recognition (HAR) is achieved\\nthrough the reception of both Signal Strength Information (RSSI) and Chann el State\\nInformation (CSI).In comparison to RSS, CSI can provide detailed chan nel frequency\\nresponse information[ 1] on multiple channels at the physical layer, oﬀering ﬁner gran-\\nularity than RSSI and the ability to distinguish multipath component s, rendering it\\nmore eﬀective in recognizing complex human movements.Owing to it s high-resolution\\ncharacteristics, CSI has emerged as a pivotal technology in the HAR domain, p ar-\\nticularly excelling in applications requiring precise capture an d analysis of human\\ndynamics.\\nThe majority of solutions for Human Activity Recognition (HAR) based on\\nChannel State Information (CSI) in speciﬁc environments employ de ep learn-\\ning techniques, including gesture recognition[ 2][3], motion detection[ 4][5], and fall\\ndetection[ 6][7].However, researchers often conduct their studies in ideal envi ronments\\nwith relatively simple Wi-Fi signal propagation. Due to the poor inte rference resis-\\ntance of Wi-Fi signals, the accuracy of these solutions may signiﬁcantly diminish\\nin more complex scenarios such as through-wall or Non-Line-of-Sight (NLOS) con -\\nditions.However, these complex scenarios often represent the pri mary application\\ncontexts for human activity recognition.The challenges encountered i n human percep-\\ntion through walls using Wi-Fi include technical limitations such as signal attenuation,\\nmultipath interference, signal noise, environmental factors like w all composition,\\ndynamic environments, as well as privacy and ethical considerations.C onsequently,\\nachieving high-accuracy human activity recognition in complex environ ments has\\nbecome a critical issue.Human Activity Recognition based on CSI fundame ntally\\ninvolves analyzing the impact of human activity on wireless signals, su ggesting that\\na potential solution to the aforementioned issues is to extract and uti lize the most\\nrepresentative features within the wireless signals.Addressin g these challenges is cru-\\ncial for the advancement of this ﬁeld.Robust algorithms, models, and fr ameworks\\nare required to mitigate the eﬀects of signal issues and adapt to dynamic envi-\\nronments.Furthermore, the latest advancements in Multiple-Inp ut Multiple-Output\\n(MIMO) communications and the utilization of Wi-Fi signals oﬀer a promis ing avenue\\nto realize this goal.\\n2', metadata={'source': 'sample.pdf', 'page': 2}),\n",
       " Document(page_content='Inthisstudy,weconductedanin-depthanalysisoftheoriginalChanne lStateInfor-\\nmation (CSI), with a particular focus on the impact of signal attenuation an d minor\\nmovements on CSI in through-wall scenarios.To fully extract feature s, we treated the\\ndata from each antenna as an independent input channel, incorporating b oth time-\\ndomain and frequency-domain information.Additionally, we employed me dian ﬁltering\\nto optimize data quality and reduce noise, coupled with the introdu ction of Gaussian\\nnoise enhancement to simulate uncertainties in real-world environ ments, eﬀectively\\nmitigating noise interference caused by minor and inadvertent move ments.These\\nstrategies collectively enhanced the reliability of the data, impro ving the model’s\\nperformance and adaptability in complex environments.\\nIn summary, this research makes the following key contributions:\\n•In addressing the challenges of datasets in through-wall scenarios, we d evised and\\napplied a data processing strategy combining median ﬁltering with Gaussian noise,\\nwhich not only eﬀectively reduced data noise but also signiﬁcantly e nhanced the\\nquality and generalizability of the data.Training with pre-processe d data led to a\\nsubstantial increase in accuracy on the original dataset.\\n•We introduced the Wi-SensiNet approach, which integrates Convoluti onal Neural\\nNetworks (CNN) with Bidirectional Long Short-Term Memory (BiLSTM) netw orks,\\nincorporating an attention mechanism to establish an advanced framework f or\\ntime-series analysis. The specially tailored BiLSTM modules proc ess deep features\\nextracted by the CNN layers, and the incorporated attention layer fur ther optimizes\\nthe model’s recognition of critical temporal steps, enhancing the ov erall accuracy\\nand robustness of the model in understanding and predicting comple x time-series\\ndata.\\n•We collected and constructed a through-wall dataset encompassing nine common\\nhuman activities, including running, sitting, standing, squattin g, falling, punching,\\nandstanding.ByapplyingtheWi-SensiNetmethod,weachievedanave rageaccuracy\\nof 99% on the original dataset, validating the eﬃcacy and precision of our approach\\nin practical applications. application.\\nThe remainder of this paper is structured as follows: Chapter 2 prov ides a compre-\\nhensive review of existing studies in the related ﬁeld,Chapter 3 details the dataset\\nemployed in this research,Chapter 4 describes the experiment al procedure and results,\\nand includes a comparative analysis with existing studies.Chapter 5 concludes the\\npaper with key ﬁndings and insights.\\n2 Related works\\nIn this chapter, we conduct a thorough review of the major works relate d to our study,\\nincluding the application of Channel State Information (CSI) data, Human Ac tivity\\nRecognition (HAR) technologies in Non-Line-of-Sight (NLOS) environments, an d the\\napplication of deep learning in this ﬁeld.In 2000, Bahl et al. [ 8] introduced Radar,\\nan innovative system for indoor positioning based on Wi-Fi Received S ignal Strength\\n(RSS), marking a pioneering use of Wi-Fi signals for sensing purpose s.Subsequently,\\nCSIdatabecameaccessibleinamultitudeofcommercialdevices,wi thprominenttools\\n3', metadata={'source': 'sample.pdf', 'page': 3}),\n",
       " Document(page_content='such as the Intel 5300 NIC [ 9], Atheros CSI Tool[ 10], and Nexmon CSI Tool[ 11] emerg-\\ning.Thesetoolsfacilitatedthecreationofnumerousplatforms,signiﬁ cantly simplifying\\nthe process of CSI data collection.CSI data, being a signal rich in env ironmental\\ninformation, has been extensively utilized for indoor activity moni toring.\\nWang et al. developed the CARM system[ 12], a human activity recognition and\\nmonitoring system based on Channel State Information (CSI), grounded in two the-\\noretical models: the CSI-Speed Model and the CSI-Activity Model . This system\\ncorrelates CSI dynamics with human movement speeds and associates t hese speeds\\nwith speciﬁc activities.This model-based approach, however, ex hibits limitations in\\nenvironmental adaptability, diversity in activity recognition, real -time processing\\neﬃciency, generalization capabilities, and in handling complex data.W ith the advance-\\nment of deep learning, researchers are increasingly leveraging this t echnology for\\nmotion recognition.Ma et al. introduced the SignFi method[ 13], a system architecture\\nprimarily based on the Channel State Information (CSI) of Wi-Fi signals, employ-\\ning Convolutional Neural Networks (CNN) for the classiﬁcation and recognition of\\nsign language gestures.The system analyzes Wi-Fi signal variations caused by ges-\\nture movements to extract features of sign language.Shi et al. describ ed a method\\nfor human activity recognition in their study[ 14].This method initially employs an\\nalgorithm to preprocess CSI signals, enhancing activity-related si gnals and reducing\\nnoise.Subsequently,itextractsfeaturesbycomputingcorrelati onsinbothtimeandfre-\\nquency domains.Utilizing these processed signals, the method aut omatically extracts\\ndeeper features through a deep learning model.\\nWhileexploringWi-Fi-basedmotionrecognitiontechnologies,researc hershavealso\\nexpanded their focus to more challenging environments, leveraging the through-wall\\ncapabilities of Wi-Fi signals for human activity recognition in such sce narios.Wang\\net al.[15] introduced a method utilizing Device-Free Sensing (DFS) t echnology in\\ncomplex scenarios, with a particular emphasis on its application in thr ough-wall\\nand Non-Line-of-Sight (NLOS) environments.The paper proposed a novel st rategy to\\nenhance DFS system performance by utilizing spatial structural in formation, inte-\\ngrating multi-dimensional features across time, frequency, and spat ial domains for\\nmore accurate identiﬁcation of target positions and activities.In conduc ting research\\non through-wall activity recognition using commercial Wi-Fi devices, we encounter\\nseveral challenges.In this paper, we propose a deep learning-based app roach that\\neﬀectively mitigates the impact of noise and environmental factors.Th is approach\\ndemonstrates strong generalization capabilities, introducing a nov el method to the\\nﬁeld of through-wall activity recognition.\\n3 Dataset\\nTo ensure the quality of the collected data and the generalization abili ty of the model,\\nwe initially conducted a series of preprocessing steps on the origi nal dataset.This\\nincluded the application of various noise reduction techniques to mi nimize noise inter-\\nference in the data, as well as the implementation of data augmentation str ategies to\\noptimize the dataset and increase sample diversity.Noise reduction p rocessing aims to\\nenhance the clarity of data signals, thereby enabling the model to mor e accurately\\n4', metadata={'source': 'sample.pdf', 'page': 4}),\n",
       " Document(page_content='capture subtle variations in human movements.Data augmentation, by si mulating\\npotential variations and disturbances, enhances the model’s adaptabil ity to new sce-\\nnarios and conditions.In the following sections, we will provide a d etailed description\\nof the noise reduction and data augmentation methods employed.\\n(a) Non-through-wall action\\n (b) Through-wall actionn\\nFig. 1: Comparison of amplitude values after normalization and variance processi ng.\\nThe horizontal axis represents the variation in time, while the vert ical axis indicates\\nthe changes in amplitude data post-normalization and variance processi ng.\\n3.1 Original Dataset\\nThe original dataset was collected using the Intel 5300 NIC, which deﬁnes the Channel\\nState Information (CSI)[ 15] as a function, given by the formula\\nHc,m\\nt=Ac,m\\ntejφc,m\\nt (1)\\nHere,Hc,m\\nt,Ac,m\\ntandφc,m\\ntrepresentthecomplexchannelresponse,amplituderesponse,\\nand phase response, respectively, for channel con antenna mat timet.In the original\\ndataset collected for this study, the dimensions of each data sample ar e deﬁned by the\\nequation Xt=NT×NR×Nsub, whereNT,NR,Nsubdenote the number of transmit-\\nting antennas, receiving antennas, and subcarriers on each antenna, re spectively.For\\nthe through-wall Channel State Information (CSI) dataset, due to the com plexity\\nof through-wall environments, the original CSI data is frequently sub ject to vari-\\nous interferences, such as signal attenuation, noise disturbances, an d environmental\\nchanges.\\nAs illustrated in Fig. 1, we utilize Normalized Variance (NV) to evaluate both non-\\nthrough-wall and through-wall data.To accentuate the diﬀerences betwe en the two\\nscenarios, we apply normalized variance analysis to through-wall and non-t hrough-\\nwall data within a speciﬁc action time window.Fig. 1ademonstrates the amplitude\\nvariations caused by a regular standing action, whereas Fig. 1bexhibits the amplitude\\n5', metadata={'source': 'sample.pdf', 'page': 5}),\n",
       " Document(page_content='(a)\\n (b)\\nFig. 2: Comparison of data before and after preprocessing. In the visual repre senta-\\ntion, (a) denotes the original data, while ( b) represents the data post-preprocessing.\\nThe x-axis signiﬁes the carrier index, the y-axis denotes the packe t index, and the z-\\naxis corresponds to the amplitude.\\nvariations of the same action under through-wall conditions.The distinc tion between\\nthe two is evident; the through-wall data exhibits a greater normaliz ed variance, indi-\\ncating an increase in the volatility of the channel state. The calculati on formula for\\nNormalized Variance (NV) is as follows:\\nNV=σ2\\nµ2(2)\\nhere,σ2represents the variance, calculated as:\\nσ2=1\\nN−1N∑\\ni=1(xi−µ)2(3)\\nµdenotes the sample mean, computed as:\\nµ=1\\nNN∑\\ni=1xi (4)\\nHere,xirepresents an individual sample value, and Ndenotes the number of sam-\\nples.Utilizing this formula allows for the quantiﬁcation of channel q uality variations\\nunder through-wall and non-through-wall conditions.The observation of a h igher\\nNormalized Variance in through-wall scenarios indicates increased signal volatility,\\npotentially caused by multipath eﬀects from walls or other environmen tal factors.This\\nincrease in volatility suggests the need for appropriate data preproce ssing strategies\\n6', metadata={'source': 'sample.pdf', 'page': 6}),\n",
       " Document(page_content='to adapt to such changes. Preprocessing may include ﬁltering, den oising, or employ-\\ning more sophisticated signal processing techniques to stabilize the signal, thereby\\nenhancing the accuracy and reliability of subsequent analyses.\\n3.2 Data Preprocessing\\nInthisstudy,weemployedamedianﬁlterfornoisereductioninCh annelStateInforma-\\ntion (CSI) data.A non-linear digital ﬁltering technique, often used in signal processing\\nto reduce noise. This method preserves edges while removing noi se, by replacing each\\nentry with the median of neighboring entries.Median ﬁlters are high ly advantageous in\\nimageandsignalprocessing,particularlyeﬀectiveineliminatingsal t-and-peppernoise,\\nwhile eﬃciently preserving the edge characteristics of images.As a nonlinear ﬁltering\\ntechnique, it is less sensitive to outliers, making it particul arly eﬀective in processing\\nsignals with anomalies or noise.The fundamental equation for median ﬁlter ing is\\ny(i) = Med{x(i−k),...,x(i+k)} (5)\\nwherex(i) represents the original signal, y(i) is the signal post-ﬁltering, and kis\\nhalf the window size. In this context, we have set the window siz e of the median ﬁlter\\nto 3x3, to eﬀectively eliminate noise while preserving the edge fe atures of the signal.\\nAdditionally, considering the potential attenuation of features due to through-wall\\nsignals, we incorporated Gaussian noise augmentation to enhance the featur e repre-\\nsentation of the dataset.Adding Gaussian Noise is a process in signal proc essing where\\nGaussian noise (a statistical noise having a probability density fun ction equal to that\\nof the normal distribution) is added to a signal. This technique is com monly used in\\nalgorithmstotestrobustnessagainstnoiseortoimprovegeneralization. Theadditionof\\nGaussian noise follows the principle of z(i) =x(i)+N(µ,σ2) In this context,, N(µ,σ2)\\nrepresents a Gaussian distribution with a mean of µand a variance denoted by ε=\\nσ2.In our experiments, we set the mean of the Gaussian noise to 0 and the s tandard\\ndeviation to 0.1, ensuring that the noise level was moderate and did not ob scure the\\ncharacteristics of the original signal.This approach not only simulates th e uncertain-\\nties of real-world environments but also enhances the data’s represe ntational capacity\\nwhile preserving the characteristics of the original signal, making i t particularly suit-\\nable for through-wall signal processing scenarios.As demonstrated in Fi g.2, we present\\na comparison of the data before and after preprocessing.\\n4 System Architecture\\nIn this study, a deep learning-based algorithmic framework is devel oped, aimed at\\nprocessing and classifying Channel State Information (CSI) data coll ected through\\nwalls. As depicted in Fig. 4, the entire processing pipeline is segmented into sev-\\neral pivotal stages: Initially, the preprocessed through-wall CSI dat a is fed into a\\nConvolutional Neural Network (CNN) module. This module leverages its mul tiple con-\\nvolutional layers to autonomously extract spatial features from the data. T he features\\noutputted by the CNN module are then reshaped to conform to the input speciﬁca-\\ntions of subsequent modules. Subsequently, the reshaped time- series data is input into\\n7', metadata={'source': 'sample.pdf', 'page': 7}),\n",
       " Document(page_content='a Bidirectional Long Short-Term Memory (BiLSTM) module. The archite cture of the\\nBiLSTM module is meticulously designed to process time-series data, with a speciﬁc\\nfocus on capturing extended dependencies in the temporal dimens ion. Following this,\\nthe output from the BiLSTM module is conveyed to a fully connected l ayer, which is\\ntasked with mapping the temporal features onto speciﬁc categories of act ions.\\nTo augment the model’s proﬁciency in interpreting time-series data, an attention\\nmechanism has been integrated. This mechanism dynamically modulate s the model’s\\nfocus across various time steps in the sequence. By assigning atten tion weights to the\\nhidden states of the Bidirectional Long Short-Term Memory (BiLSTM) mo dule, the\\nmodel intensively processes dynamic features that are essential for the classiﬁcation\\ntask. This enhancement notably escalates the model’s accuracy in rec ognizing human\\nactivities through walls, especially in environments with complex signal patterns.\\nConsequently, the proposed CNN-BiLSTM framework, enriched with the attention\\nmechanism, amalgamates the strengths of spatial feature extraction and tem poral\\ndependency capture. Furthermore, it attains an in-depth comprehe nsion of time-series\\ndata via the incorporation of the attention model. This culminates in a novel and\\neﬃcacious methodology for human activity recognition in through-wall scen arios.\\n4.1 Convolutional Neural Network\\nIn our research, for the three-dimensional through-wall Channel Stat e Informa-\\ntion (CSI) dataset, we employed a two-dimensional Convolutional Neural Ne twork\\n(CNN2D) module to perform feature extraction tasks.This dataset posses ses dimen-\\nsions of 3x500x30, corresponding respectively to the number of antennas, t ime steps,\\nand amplitude information for each antenna.The design of the CNN2D module sp eciﬁ-\\ncally accounts for the unique structure of CSI data, aiming to eﬃcient ly extract spatial\\nfeatures embedded within the time-series data.\\nAs depicted in Fig. 3, the CNN2D module comprises two convolutional layers, each\\nfollowed by a Rectiﬁed Linear Unit (ReLU) and a max pooling layer.The ﬁr st con-\\nvolutional layer utilizes 3x3 kernels (with a stride of 1 and padding of 1) to process\\nsignals from diﬀerent antennas, generating feature maps containing pri mary spatial\\nfeatures.Subsequently, the ReLU activation function is applied to introduce nonlin-\\nearity, aiding in capturing more complex data patterns. Subsequent ly, a max pooling\\nlayer with 2x2 kernels and a stride of 2 is utilized to reduce the s patial dimensions of\\nConv2D Conv2D MAX-POOL MAX-POOL\\nFig. 3: Schematic Diagram of the CNN Module.\\n8', metadata={'source': 'sample.pdf', 'page': 8}),\n",
       " Document(page_content='Fig. 4: Algorithm process framework.\\nthe feature maps while retaining essential features.This downsam pling step is aimed\\nat reducing computational load and preventing overﬁtting.The second convolutional\\nlayer further processes the features, and another ReLU activation fu nction is employed\\nto maintain nonlinearity.Then, max pooling is applied again to further reduce the\\nsize of the feature maps, facilitating higher-level feature abstract ion.The design of\\nthis CNN module takes into account the uniqueness of through-wall CSI data. With\\ncarefully selected parameters and layer structure, it ensures t hat the network eﬀec-\\ntively extracts crucial spatiotemporal features from the data, signiﬁc antly enhancing\\nthe accuracy and eﬃciency of subsequent classiﬁcation tasks.\\n4.2 BiLSTM\\nIn the architecture we propose, a Bidirectional Long Short-Term Memor y network\\n(BiLSTM) is employed following the Convolutional Neural Network (CNN) mo dule to\\neﬀectively process sequential data. As illustrated in Fig. 5,the BiLSTM enhances the\\nlearningofsequencefeaturesbycapturingthecontextualinformati onofthetimeseries\\nfrom both forward and backward directions simultaneously. In its speci ﬁc implemen-\\ntation, the BiLSTM consists of a single LSTM layer, with the input fe ature dimension\\nspeciﬁed as the reshaped output of the preceding layer, while the dimension of the\\nhidden layer is set to 64. Furthermore, we ensure that the batch siz e of the input\\nand output tensors is positioned in the ﬁrst dimension. The bidirec tional processing\\ncapability of the LSTM is also activated. This forms a comprehensive fr amework for\\n9', metadata={'source': 'sample.pdf', 'page': 9}),\n",
       " Document(page_content='analyzing time-series data. The LSTM module is renowned for its eﬃc iency in cap-\\nturing long-term dependencies in sequential data and is speciﬁcal ly tailored to handle\\nthe feature-rich outputs extracted by the preceding CNN layer. A t each time step t,\\nthe forward LSTM segment computes the hidden state− →htusing the current input xt\\nand the hidden state−−→ht−1from the previous time step, while the backward LSTM\\ncalculates← −htbased on the same input and the hidden state←−−ht+1from the subsequent\\ntime step. The output htof the bidirectional LSTM at each time step is a concate-\\nnation of the forward and backward hidden states, formulated as ht= [− →ht;← −ht]. This\\nstructure allows the model to integrate the information of the entir e input sequence\\nat each time step, thus more comprehensively capturing the long-ter m dependencies\\nin the sequence.\\n4.3 Attention mechanism\\nAdditionally, our model incorporates an attention mechanism, aimed at fur ther\\nenhancing the identiﬁcation of key sequential information. This att ention mechanism\\nassignsaweighttoeachtimestepoutputofthebidirectionalLSTM,the rebyemphasiz-\\ning more signiﬁcant features while suppressing less relevant inf ormation. Speciﬁcally,\\nwe initially transform the BiLSTM output at each time step into a scalar using a linear\\nlayer, a step that can be viewed as scoring the importance of each time s tep. Subse-\\nquently, we apply a softmax function to normalize these scores, ensu ring that the sum\\nFig. 5: BILSTM with Integrated Attention Mechanism.\\n10', metadata={'source': 'sample.pdf', 'page': 10}),\n",
       " Document(page_content='Fig. 6: System Workﬂow.\\nof attention weights across all time steps equals 1. This process can be r epresented as:\\nat= softmax( Wattn·ht+battn) (6)\\nHere,atrepresents the attention weight for time step t, whileWattnandbattnare the\\nweight and bias of the linear layer, respectively, and htis the output of the BiLSTM\\nat time step t. Subsequently, we compute the context vector ctas the sum of the\\nweighted BiLSTM outputs:\\nc=T∑\\nt=1at·ht (7)\\nThe context vector cprovides a weighted representation of the sequence, where the\\ncontribution of each time step is determined based on its relative im portance. This\\nenables the model to utilize more reﬁned and targeted sequence feat ures in subsequent\\nfully connected layers.\\n5 Experiments And Results\\nIn this section, we detail our experimental procedures and the corr esponding results.\\n5.1 Dataset Collection\\nWe meticulously designed and constructed a data collection experim ent speciﬁcally\\ntargeting through-wall propagation scenarios, aimed at augmenting our unders tanding\\nand simulation of wireless signal behavior in real-world environments .As depicted in\\nFig.7, the transmitter (TX) is strategically placed in an outdoor setting to emulate\\nthe reception of wireless signals within a home or oﬃce environment.C onversely, the\\nreceiver(RX)ispositionedindoors,ensuringthatthesignalsitre ceivesmustpenetrate\\nthe walls of the building.\\n11', metadata={'source': 'sample.pdf', 'page': 11}),\n",
       " Document(page_content='Fig. 7: Dataset collection scenario.\\nDuring the experimental phase, the participants engaged in a variety of pre-deﬁned\\nmotions within an indoor setting, encompassing fundamental activitie s like walking,\\nrunning, and boxing, along with a range of everyday actions. This approach w as\\ndesigned to maximize the coverage of typical human activities within the collected\\ndata. Each activity was meticulously labeled and linked with concurre nt wireless sig-\\nnal data collection. The primary objective was to furnish a comprehen sive training\\nand testing dataset for the development of advanced motion classiﬁcation al gorithms.\\nWithin the experimental setup, particular emphasis was placed on th e pathways\\nof wireless signal propagation and potential environmental obstacles. Key p arameters,\\nincluding the direct line distance between the transmitter and receiver, the material\\nproperties and thickness of walls, as well as the relative indoor and out door position-\\ning, were meticulously documented and analyzed. Furthermore, in or der to simulate\\nthe propagation of wireless signals in varied residential and occupational settings more\\naccurately, the positions of the subjects were varied in accordance wi th their move-\\nments to assess the impact of diverse factors on the behavior of wirele ss signals.\\nEach activity was accurately tagged and associated with the simultaneous ly collected\\nwireless signal data, with the aim of enriching the training and testi ng datasets for\\nforthcoming motion classiﬁcation algorithms.\\n12', metadata={'source': 'sample.pdf', 'page': 12}),\n",
       " Document(page_content='(a) Performance on the test set post-\\npreprocessing\\n(b) Performance on the test set with original\\ndata\\nFig. 8: Confusion Matrix for Through-Wall Activity Recognition.The horizontal ax is\\nrepresents predicted labels, while the vertical axis denotes th e true labels.\\n5.2 System Workﬂow\\nIn our study, as illustrated in Fig. 6, we employed a human activity recognition system\\nbased on Channel State Information (CSI) data.The system’s workﬂow enc ompasses\\nseveral stages: initially acquiring raw CSI data through collection de vices, followed\\nby data preprocessing involving denoising and data augmentation to en hance data\\nquality.Subsequently, the preprocessed data is fed into a dee p learning model that\\nintegrates a Convolutional Neural Network (CNN) with a Bidirectional Long Shor t-\\nTerm Memory (BiLSTM) network equipped with an attention mechanism, responsible\\nfor feature extraction and time series analysis.Ultimately, the mode l outputs a prob-\\nability distribution for action classiﬁcation, achieving precise id entiﬁcation of human\\nactivities.\\n00.20.40.60.811.2\\nbox fall run sit squat stand walk\\nWi-SensiNet\\n CNN\\nLSTM\\nFig. 9: Accuracy of Three Models in Recognizing Various Actions.\\n13', metadata={'source': 'sample.pdf', 'page': 13}),\n",
       " Document(page_content='5.3 Experimental Results\\nIn this section, we will present a detailed exposition of the resul ts obtained from our\\nexperimental study.The experiment is designed to validate the e ﬃcacy of our pro-\\nposed model in classifying human activities.By comparing the perf ormance of the\\nmodel under diﬀerent conﬁgurations, we are able to accurately assess t he impact of\\nvarious factors on the classiﬁcation accuracy. As illustrated in Fig. 8, we conducted\\na comparative analysis of the model’s performance on both preprocessed and origi-\\nnal datasets.The results of the confusion matrix clearly demonstrate t hat the model\\ntrained on datasets subjected to noise reduction and data augmentation ex hibits supe-\\nrior classiﬁcation accuracy on the original dataset.Notably, the diagonal eleme nts,\\nrepresenting the percentage of correct classiﬁcations, are generally higher in the confu-\\nsion matrix of the preprocessed dataset compared to the original dataset. This ﬁnding\\nvalidates the eﬀectiveness of our data preprocessing strategy, aﬃr ming its signiﬁcant\\nrole in enhancing the model’s generalization capability on unseen data. Fig.9presents\\nTable 1:ComparisonofwallpenetratingHARusingmachinelearningandrecogniti on\\ntechniques.\\nName Method Activity Hardware Accuracy\\nWi-SensiNet CNN-\\nBiLSTM(attention)Running, Sitting,\\nStanding, Squatting,\\nFalling, Punching,\\nWalkingWiFi devices 99%\\nTW-See[ 16] BP-network Walking, falling,\\nwaving, boxing,\\nstanding up, sitting\\ndown, emptyWiFi devices 94.46%\\nWiHACS[ 17] SVM(one wall) Sitting, standing,\\nwalking, squatting,\\nfalling, lying down,\\nstanding up after lyingWiFi devices 92%\\nRbHAR[ 18] Adaptive\\nthresholdingwalking, sitting,\\nstanding, picking up an\\nobject, drinking,fallingRadar sensors 93%\\na comparative analysis of the accuracy of three distinct models in recogn izing seven\\ndiﬀerent activities.These activities include boxing, falling, running, sitting, squatting,\\nstanding, and walking.The three models are Wi-SensiNet, CNN, and LSTM re spec-\\ntively. It is observable that, in most activity recognition tasks, the accuracy of the\\nWi-SensiNet model slightly surpasses the other two models.Parti cularly in the recogni-\\ntion of falling activity, the Wi-SensiNet model demonstrates a signi ﬁcant advantage.In\\ncontrast, the performance of CNN and LSTM is relatively similar across all ac tivities,\\nthough CNN exhibits a slight edge in recognizing squatting and standing actions.This\\nchart signiﬁcantly highlights the performance disparities among diﬀe rent models in\\nactivity recognition tasks and provides a quantitative basis for furth er discussion and\\nanalytical research.\\n14', metadata={'source': 'sample.pdf', 'page': 14}),\n",
       " Document(page_content='Fig. 10: Accuracy performance of diﬀerent datasets.\\nAs depicted in Table 1, we conducted a comparative analysis with other literature\\nthat utilizes machine learning and recognition techniques for through -wall Human\\nActivity Recognition (HAR).These approaches include systems based on W iFi devices\\nand radar sensors, each targeting the recognition of various daily activiti es.By con-\\ntrasting these various methods, we assessed their respective pe rformances, and the\\ncomparison has illuminated the advancements made in the ﬁeld of human act ivity\\nrecognition through diﬀerent technological approaches, also oﬀering valuab le insights\\nfor our research.\\nAsdepictedinFig. 10,wepresentacomparisonoftheperformanceofthreemodels:\\nWi-SensiNet, CNN, and LSTM across diﬀerent datasets and preprocessing methods.\\nNotably, the Wi-SensiNet model consistently outperforms the other m odels across all\\ndatasets, as indicated by the higher accuracy metric. Additionally, th e preprocessing\\nmethod combining median ﬁltering with Gaussian noise enhancement appears to sig-\\nniﬁcantly improve model generalization, as reﬂected by the increas ed accuracy rates\\nacross datasets when this method is employed. Furthermore, the rob ustness of the Wi-\\nSensiNet model is evident from its sustained high accuracy irrespe ctive of the dataset\\npartitioning rules applied. This graph eloquently demonstrates th e superiority of the\\nWi-SensiNet model in terms of accuracy and generalization capabilities , as well as its\\nrobustness to diﬀerent data division strategies.\\n6 Conclusion\\nIn summary, this study developed an innovative human activity recogn ition system\\nbased on Channel State Information (CSI), speciﬁcally targeting activi ty detection\\nunder Non-Line-of-Sight (NLOS) conditions. The system employs state- of-the-art\\n15', metadata={'source': 'sample.pdf', 'page': 15}),\n",
       " Document(page_content='signal processing techniques, signiﬁcantly enhancing the predi ctive capability for\\nthrough-wall human activity recognition using WiFi sensing technology . The primary\\nexperimental focus was on minimizing the impact of prediction error s through walls\\non accuracy in indoor environments. Data denoising and enhancement st rategies were\\nemployed, optimizing the quality of the dataset and boosting the mod el’s adaptability\\nto new environments. Technically, the model amalgamates the spatial f eature extrac-\\ntion prowess of Convolutional Neural Networks (CNN) with the temporal analysi s\\nproﬁciency of Bidirectional Long Short-Term Memory (BiLSTM) networks , further\\naugmented by an attention mechanism. The experimental results unde rscore the high\\naccuracy of this approach in human activity recognition, demonstrating it s viability\\nin practical applications.\\nReferences\\n[1] Zhou, Z., Wu, C., Yang, Z., Liu, Y.: Sensorless sensing with wiﬁ. T singhua Science\\nand Technology 20(1), 1–6 (2015)\\n[2] Yang, J., Zou, H., Zhou, Y., Xie, L.: Learning gestures from wiﬁ: A siamese\\nrecurrent convolutional architecture. IEEE Internet of Things Jour nal6(6),\\n10763–10772 (2019)\\n[3] Li, C., Liu, M., Cao, Z.: Wihf: Enable user identiﬁed gesture recogn ition with\\nwiﬁ. In: IEEE INFOCOM 2020-IEEE Conference on Computer Communications,\\npp. 586–595 (2020). IEEE\\n[4] Ding, X., Jiang, T., Zhong, Y., Wu, S., Yang, J., Xue, W.: Improving wiﬁ -based\\nhuman activity recognition with adaptive initial state via one-shot lear ning. In:\\n2021 IEEE Wireless Communications and Networking Conference (WCNC), pp .\\n1–6 (2021). IEEE\\n[5] Zou, H., Zhou, Y., Yang, J., Jiang, H., Xie, L., Spanos, C.J.: Deepsense: D evice-\\nfreehumanactivityrecognitionviaautoencoderlong-termrecurren tconvolutional\\nnetwork. In: 2018 IEEE International Conference on Communications (ICC ), pp.\\n1–6 (2018). IEEE\\n[6] Palipana, S., Rojas, D., Agrawal, P., Pesch, D.: Falldeﬁ: Ubiquitous fall detection\\nusing commodity wi-ﬁ devices. Proceedings of the ACM on Interacti ve, Mobile,\\nWearable and Ubiquitous Technologies 1(4), 1–25 (2018)\\n[7] Ding, J., Wang, Y.: A wiﬁ-based smart home fall detection system usin g recur-\\nrent neural network. IEEE Transactions on Consumer Electronics 66(4), 308–317\\n(2020)\\n[8] Bahl, P., Padmanabhan, V.N.: Radar: An in-building rf-based user locat ion and\\ntrackingsystem.In:ProceedingsIEEEINFOCOM2000.ConferenceonComp uter\\nCommunications. Nineteenth Annual Joint Conference of the IEEE Comput er\\n16', metadata={'source': 'sample.pdf', 'page': 16}),\n",
       " Document(page_content='and Communications Societies (Cat. No. 00CH37064), vol. 2, pp. 775–784 (2000).\\nIeee\\n[9] Halperin, D., Hu, W., Sheth, A., Wetherall, D.: Tool release: Gathe ring 802.11 n\\ntraces with channel state information. ACM SIGCOMM computer communi ca-\\ntion review 41(1), 53–53 (2011)\\n[10] Xie, Y., Li, Z., Li, M.: Precise power delay proﬁling with commodi ty wiﬁ. In:\\nProceedings of the 21st Annual International Conference on Mobile Computi ng\\nand Networking, pp. 53–64 (2015)\\n[11] Gringoli, F., Schulz, M., Link, J., Hollick, M.: Free your csi: A c hannel state infor-\\nmation extraction platform for modern wi-ﬁ chipsets. In: Proceedin gs of the 13th\\nInternational Workshop on Wireless Network Testbeds, Experimental E valuation\\n& Characterization, pp. 21–28 (2019)\\n[12] Wang, W., Liu, A.X., Shahzad, M., Ling, K., Lu, S.: Device-free human act ivity\\nrecognition using commercial wiﬁ devices. IEEE Journal on Selected Ar eas in\\nCommunications 35(5), 1118–1131 (2017)\\n[13] Ma, Y., Zhou, G., Wang, S., Zhao, H., Jung, W.: Signﬁ: Sign language recogni-\\ntion using wiﬁ. Proceedings of the ACM on Interactive, Mobile, Wearab le and\\nUbiquitous Technologies 2(1), 1–21 (2018)\\n[14] Shi, Z., Zhang, J.A., Xu, R., Cheng, Q.: Deep learning networks for h uman activ-\\nity recognition with csi correlation feature extraction. In: ICC 2019-2019 IE EE\\nInternational Conference on Communications (ICC), pp. 1–6 (2019). IEEE\\n[15] Wang, J., Zhang, L., Gao, Q., Pan, M., Wang, H.: Device-free wireless se nsing\\nin complex scenarios using spatial structural information. IEEE Trans actions on\\nWireless Communications 17(4), 2432–2442 (2018)\\n[16] Wu, X., Chu, Z., Yang, P., Xiang, C., Zheng, X., Huang, W.: Tw-see: Human\\nactivity recognition through the wall with commodity wi-ﬁ devices. I EEE\\nTransactions on Vehicular Technology 68(1), 306–319 (2018)\\n[17] Chowdhury, T.Z., Leung, C., Miao, C.Y.: Wihacs: Leveraging wiﬁ for hu man\\nactivity classiﬁcation using ofdm subcarriers’ correlation. In: 2017 IE EE Global\\nConference on Signal and Information Processing (GlobalSIP), pp. 338–342\\n(2017). IEEE\\n[18] Li, Z., Le Kernec, J., Abbasi, Q., Fioranelli, F., Yang, S., Romain, O. : Radar-\\nbased human activity recognition with adaptive thresholding towards r esource\\nconstrained platforms. Scientiﬁc Reports 13(1), 3473 (2023)\\n17', metadata={'source': 'sample.pdf', 'page': 17})]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader=PyPDFLoader(\"sample.pdf\")\n",
    "pdf_document=loader.load()\n",
    "pdf_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Wi-SensiNet: Through-Wall Human Activity\\nRecognition Based on WiFi Sensing\\nFu Xiaoyi\\xa0\\nSouthwest University\\nWang Chenlu\\xa0\\nSouthwest University\\nLi Shenglin\\xa0 \\n \\nSouthwest University\\nResearch Article\\nKeywords:  Human activity recognition, Deep learning, WiFi se nsing, Through wall,Channel state\\ninformation\\nPosted Date:  March 19th, 2024\\nDOI:  https://doi.org/10.21203/rs.3.rs-4106293/v1\\nLicense:  \\uf25e \\uf4e7 This work is licensed under a Creative Commons Att ribution 4.0 International License. \\xa0\\nRead Full License\\nAdditional Declarations:  No competing interests reported.', metadata={'source': 'sample.pdf', 'page': 0}),\n",
       " Document(page_content='Wi-SensiNet: Through-Wall Human Activity\\nRecognition Based on WiFi Sensing\\nFu Xiaoyi1, Wang Chenlu1, Li Shenglin1*\\n1*College of Artiﬁcial Intelligence, Southwest University, Chongqing,\\n400715, China.\\n*Corresponding author(s). E-mail(s): lishenglin@swu.edu.cn ;\\nContributing authors: swufuxiaoyi@163.com ;\\nAbstract\\nWith the advancement of Wi-Fi sensing technology, its signi ﬁcant beneﬁts in\\nconvenient operation and privacy protection have become appare nt, particularly\\nin ﬁelds like smart homes, medical monitoring, and security surv eillance, where\\nthe application prospects of Human Activity Recognition (HA R) technology are\\nincreasingly broad. This study focuses on a novel approach to HAR using Wi-Fi\\nChannel State Information (CSI), especially under complex co nditions such as\\nNon-Line of Sight (NLoS) paths and through-wall transmission s. Traditionally,\\nmost research has concentrated on Line of Sight (LoS) path HAR, s ensitive to', metadata={'source': 'sample.pdf', 'page': 1}),\n",
       " Document(page_content='Non-Line of Sight (NLoS) paths and through-wall transmission s. Traditionally,\\nmost research has concentrated on Line of Sight (LoS) path HAR, s ensitive to\\nenvironmental changes, while the NLoS path signals, especia lly through-wall sig-\\nnals, present unpredictability due to weak reﬂections caused b y walls. Addressing\\nthis issue, we propose Wi-SensiNet, an innovative deep learni ng-based method\\nthat combines the spatial feature extraction capabilities of C onvolutional Neural\\nNetworks (CNN) with the temporal sequence processing power of B idirectional\\nLong Short-Term Memory networks (BiLSTM). This method also inco rporates\\nan attention mechanism to enhance the accuracy of human activ ity recogni-\\ntion in complex environments. Wi-SensiNet is specially desi gned for through-wall\\nsettings, eﬀectively handling the complexity of CSI data, a nd achieving accu-\\nrate through-wall human activity detection. In our experiment s, we collected', metadata={'source': 'sample.pdf', 'page': 1}),\n",
       " Document(page_content='settings, eﬀectively handling the complexity of CSI data, a nd achieving accu-\\nrate through-wall human activity detection. In our experiment s, we collected\\na through-wall CSI dataset comprising seven common activitie s, including run-\\nning, sitting, standing, squatting, falling, punching, and walking, and veriﬁed\\nWi-SensiNet’s average accuracy exceeded 99% on the original te st set. These\\nresults not only demonstrate the model’s robustness and high acc uracy in han-\\ndling HAR tasks in complex environments but also highlight th e potential of\\nCNN and BiLSTM working in tandem to enhance performance.\\nKeywords: Human activity recognition, Deep learning, WiFi sensing, Th rough\\nwall,Channel state information\\n1', metadata={'source': 'sample.pdf', 'page': 1}),\n",
       " Document(page_content='1 Introduction\\nIn recent years, Human Activity Recognition (HAR) has increasingly found ap pli-\\ncations in ﬁelds such as smart homes, medical monitoring, and security s urveil-\\nlance.Particularly with the proliferation of smart devices and the adv ancement of\\nInternet of Things (IoT) technologies, Wi-Fi sensing technology has be en increasingly\\napplied, harnessing a detectable feature within Wi-Fi signals kno wn as Channel State\\nInformation (CSI).This type of data can intricately illustrate how w ireless signals\\nare transmitted between sending and receiving devices, where m ovement of a person\\nwithin the Wi-Fi signal propagation path induces changes in the signal’s p hase and\\namplitude.These alterations are reﬂected in the CSI, a characteris tic of Wi-Fi sig-\\nnals, oﬀering detailed insights into the signal propagation path, transmi ssion time,\\nand attenuation.Consequently, by analyzing the variations in CSI data, on e can infer', metadata={'source': 'sample.pdf', 'page': 2}),\n",
       " Document(page_content='nals, oﬀering detailed insights into the signal propagation path, transmi ssion time,\\nand attenuation.Consequently, by analyzing the variations in CSI data, on e can infer\\nchanges in human movement and positioning.Compared to traditional metho ds reliant\\non visual or wearable sensors, this approach oﬀers a more covert and non-lin e-of-\\nsight dependent solution.Wi-Fi-based Human Activity Recognition (HAR) is achieved\\nthrough the reception of both Signal Strength Information (RSSI) and Chann el State\\nInformation (CSI).In comparison to RSS, CSI can provide detailed chan nel frequency\\nresponse information[ 1] on multiple channels at the physical layer, oﬀering ﬁner gran-\\nularity than RSSI and the ability to distinguish multipath component s, rendering it\\nmore eﬀective in recognizing complex human movements.Owing to it s high-resolution\\ncharacteristics, CSI has emerged as a pivotal technology in the HAR domain, p ar-', metadata={'source': 'sample.pdf', 'page': 2}),\n",
       " Document(page_content='more eﬀective in recognizing complex human movements.Owing to it s high-resolution\\ncharacteristics, CSI has emerged as a pivotal technology in the HAR domain, p ar-\\nticularly excelling in applications requiring precise capture an d analysis of human\\ndynamics.\\nThe majority of solutions for Human Activity Recognition (HAR) based on\\nChannel State Information (CSI) in speciﬁc environments employ de ep learn-\\ning techniques, including gesture recognition[ 2][3], motion detection[ 4][5], and fall\\ndetection[ 6][7].However, researchers often conduct their studies in ideal envi ronments\\nwith relatively simple Wi-Fi signal propagation. Due to the poor inte rference resis-\\ntance of Wi-Fi signals, the accuracy of these solutions may signiﬁcantly diminish\\nin more complex scenarios such as through-wall or Non-Line-of-Sight (NLOS) con -\\nditions.However, these complex scenarios often represent the pri mary application', metadata={'source': 'sample.pdf', 'page': 2}),\n",
       " Document(page_content='in more complex scenarios such as through-wall or Non-Line-of-Sight (NLOS) con -\\nditions.However, these complex scenarios often represent the pri mary application\\ncontexts for human activity recognition.The challenges encountered i n human percep-\\ntion through walls using Wi-Fi include technical limitations such as signal attenuation,\\nmultipath interference, signal noise, environmental factors like w all composition,\\ndynamic environments, as well as privacy and ethical considerations.C onsequently,\\nachieving high-accuracy human activity recognition in complex environ ments has\\nbecome a critical issue.Human Activity Recognition based on CSI fundame ntally\\ninvolves analyzing the impact of human activity on wireless signals, su ggesting that\\na potential solution to the aforementioned issues is to extract and uti lize the most\\nrepresentative features within the wireless signals.Addressin g these challenges is cru-', metadata={'source': 'sample.pdf', 'page': 2}),\n",
       " Document(page_content='a potential solution to the aforementioned issues is to extract and uti lize the most\\nrepresentative features within the wireless signals.Addressin g these challenges is cru-\\ncial for the advancement of this ﬁeld.Robust algorithms, models, and fr ameworks\\nare required to mitigate the eﬀects of signal issues and adapt to dynamic envi-\\nronments.Furthermore, the latest advancements in Multiple-Inp ut Multiple-Output\\n(MIMO) communications and the utilization of Wi-Fi signals oﬀer a promis ing avenue\\nto realize this goal.\\n2', metadata={'source': 'sample.pdf', 'page': 2}),\n",
       " Document(page_content='Inthisstudy,weconductedanin-depthanalysisoftheoriginalChanne lStateInfor-\\nmation (CSI), with a particular focus on the impact of signal attenuation an d minor\\nmovements on CSI in through-wall scenarios.To fully extract feature s, we treated the\\ndata from each antenna as an independent input channel, incorporating b oth time-\\ndomain and frequency-domain information.Additionally, we employed me dian ﬁltering\\nto optimize data quality and reduce noise, coupled with the introdu ction of Gaussian\\nnoise enhancement to simulate uncertainties in real-world environ ments, eﬀectively\\nmitigating noise interference caused by minor and inadvertent move ments.These\\nstrategies collectively enhanced the reliability of the data, impro ving the model’s\\nperformance and adaptability in complex environments.\\nIn summary, this research makes the following key contributions:\\n•In addressing the challenges of datasets in through-wall scenarios, we d evised and', metadata={'source': 'sample.pdf', 'page': 3}),\n",
       " Document(page_content='In summary, this research makes the following key contributions:\\n•In addressing the challenges of datasets in through-wall scenarios, we d evised and\\napplied a data processing strategy combining median ﬁltering with Gaussian noise,\\nwhich not only eﬀectively reduced data noise but also signiﬁcantly e nhanced the\\nquality and generalizability of the data.Training with pre-processe d data led to a\\nsubstantial increase in accuracy on the original dataset.\\n•We introduced the Wi-SensiNet approach, which integrates Convoluti onal Neural\\nNetworks (CNN) with Bidirectional Long Short-Term Memory (BiLSTM) netw orks,\\nincorporating an attention mechanism to establish an advanced framework f or\\ntime-series analysis. The specially tailored BiLSTM modules proc ess deep features\\nextracted by the CNN layers, and the incorporated attention layer fur ther optimizes\\nthe model’s recognition of critical temporal steps, enhancing the ov erall accuracy', metadata={'source': 'sample.pdf', 'page': 3}),\n",
       " Document(page_content='extracted by the CNN layers, and the incorporated attention layer fur ther optimizes\\nthe model’s recognition of critical temporal steps, enhancing the ov erall accuracy\\nand robustness of the model in understanding and predicting comple x time-series\\ndata.\\n•We collected and constructed a through-wall dataset encompassing nine common\\nhuman activities, including running, sitting, standing, squattin g, falling, punching,\\nandstanding.ByapplyingtheWi-SensiNetmethod,weachievedanave rageaccuracy\\nof 99% on the original dataset, validating the eﬃcacy and precision of our approach\\nin practical applications. application.\\nThe remainder of this paper is structured as follows: Chapter 2 prov ides a compre-\\nhensive review of existing studies in the related ﬁeld,Chapter 3 details the dataset\\nemployed in this research,Chapter 4 describes the experiment al procedure and results,\\nand includes a comparative analysis with existing studies.Chapter 5 concludes the\\npaper with key ﬁndings and insights.', metadata={'source': 'sample.pdf', 'page': 3}),\n",
       " Document(page_content='and includes a comparative analysis with existing studies.Chapter 5 concludes the\\npaper with key ﬁndings and insights.\\n2 Related works\\nIn this chapter, we conduct a thorough review of the major works relate d to our study,\\nincluding the application of Channel State Information (CSI) data, Human Ac tivity\\nRecognition (HAR) technologies in Non-Line-of-Sight (NLOS) environments, an d the\\napplication of deep learning in this ﬁeld.In 2000, Bahl et al. [ 8] introduced Radar,\\nan innovative system for indoor positioning based on Wi-Fi Received S ignal Strength\\n(RSS), marking a pioneering use of Wi-Fi signals for sensing purpose s.Subsequently,\\nCSIdatabecameaccessibleinamultitudeofcommercialdevices,wi thprominenttools\\n3', metadata={'source': 'sample.pdf', 'page': 3}),\n",
       " Document(page_content='such as the Intel 5300 NIC [ 9], Atheros CSI Tool[ 10], and Nexmon CSI Tool[ 11] emerg-\\ning.Thesetoolsfacilitatedthecreationofnumerousplatforms,signiﬁ cantly simplifying\\nthe process of CSI data collection.CSI data, being a signal rich in env ironmental\\ninformation, has been extensively utilized for indoor activity moni toring.\\nWang et al. developed the CARM system[ 12], a human activity recognition and\\nmonitoring system based on Channel State Information (CSI), grounded in two the-\\noretical models: the CSI-Speed Model and the CSI-Activity Model . This system\\ncorrelates CSI dynamics with human movement speeds and associates t hese speeds\\nwith speciﬁc activities.This model-based approach, however, ex hibits limitations in\\nenvironmental adaptability, diversity in activity recognition, real -time processing\\neﬃciency, generalization capabilities, and in handling complex data.W ith the advance-\\nment of deep learning, researchers are increasingly leveraging this t echnology for', metadata={'source': 'sample.pdf', 'page': 4}),\n",
       " Document(page_content='eﬃciency, generalization capabilities, and in handling complex data.W ith the advance-\\nment of deep learning, researchers are increasingly leveraging this t echnology for\\nmotion recognition.Ma et al. introduced the SignFi method[ 13], a system architecture\\nprimarily based on the Channel State Information (CSI) of Wi-Fi signals, employ-\\ning Convolutional Neural Networks (CNN) for the classiﬁcation and recognition of\\nsign language gestures.The system analyzes Wi-Fi signal variations caused by ges-\\nture movements to extract features of sign language.Shi et al. describ ed a method\\nfor human activity recognition in their study[ 14].This method initially employs an\\nalgorithm to preprocess CSI signals, enhancing activity-related si gnals and reducing\\nnoise.Subsequently,itextractsfeaturesbycomputingcorrelati onsinbothtimeandfre-\\nquency domains.Utilizing these processed signals, the method aut omatically extracts\\ndeeper features through a deep learning model.', metadata={'source': 'sample.pdf', 'page': 4}),\n",
       " Document(page_content='quency domains.Utilizing these processed signals, the method aut omatically extracts\\ndeeper features through a deep learning model.\\nWhileexploringWi-Fi-basedmotionrecognitiontechnologies,researc hershavealso\\nexpanded their focus to more challenging environments, leveraging the through-wall\\ncapabilities of Wi-Fi signals for human activity recognition in such sce narios.Wang\\net al.[15] introduced a method utilizing Device-Free Sensing (DFS) t echnology in\\ncomplex scenarios, with a particular emphasis on its application in thr ough-wall\\nand Non-Line-of-Sight (NLOS) environments.The paper proposed a novel st rategy to\\nenhance DFS system performance by utilizing spatial structural in formation, inte-\\ngrating multi-dimensional features across time, frequency, and spat ial domains for\\nmore accurate identiﬁcation of target positions and activities.In conduc ting research\\non through-wall activity recognition using commercial Wi-Fi devices, we encounter', metadata={'source': 'sample.pdf', 'page': 4}),\n",
       " Document(page_content='more accurate identiﬁcation of target positions and activities.In conduc ting research\\non through-wall activity recognition using commercial Wi-Fi devices, we encounter\\nseveral challenges.In this paper, we propose a deep learning-based app roach that\\neﬀectively mitigates the impact of noise and environmental factors.Th is approach\\ndemonstrates strong generalization capabilities, introducing a nov el method to the\\nﬁeld of through-wall activity recognition.\\n3 Dataset\\nTo ensure the quality of the collected data and the generalization abili ty of the model,\\nwe initially conducted a series of preprocessing steps on the origi nal dataset.This\\nincluded the application of various noise reduction techniques to mi nimize noise inter-\\nference in the data, as well as the implementation of data augmentation str ategies to\\noptimize the dataset and increase sample diversity.Noise reduction p rocessing aims to\\nenhance the clarity of data signals, thereby enabling the model to mor e accurately\\n4', metadata={'source': 'sample.pdf', 'page': 4}),\n",
       " Document(page_content='capture subtle variations in human movements.Data augmentation, by si mulating\\npotential variations and disturbances, enhances the model’s adaptabil ity to new sce-\\nnarios and conditions.In the following sections, we will provide a d etailed description\\nof the noise reduction and data augmentation methods employed.\\n(a) Non-through-wall action\\n (b) Through-wall actionn\\nFig. 1: Comparison of amplitude values after normalization and variance processi ng.\\nThe horizontal axis represents the variation in time, while the vert ical axis indicates\\nthe changes in amplitude data post-normalization and variance processi ng.\\n3.1 Original Dataset\\nThe original dataset was collected using the Intel 5300 NIC, which deﬁnes the Channel\\nState Information (CSI)[ 15] as a function, given by the formula\\nHc,m\\nt=Ac,m\\ntejφc,m\\nt (1)\\nHere,Hc,m\\nt,Ac,m\\ntandφc,m\\ntrepresentthecomplexchannelresponse,amplituderesponse,\\nand phase response, respectively, for channel con antenna mat timet.In the original', metadata={'source': 'sample.pdf', 'page': 5}),\n",
       " Document(page_content='Hc,m\\nt=Ac,m\\ntejφc,m\\nt (1)\\nHere,Hc,m\\nt,Ac,m\\ntandφc,m\\ntrepresentthecomplexchannelresponse,amplituderesponse,\\nand phase response, respectively, for channel con antenna mat timet.In the original\\ndataset collected for this study, the dimensions of each data sample ar e deﬁned by the\\nequation Xt=NT×NR×Nsub, whereNT,NR,Nsubdenote the number of transmit-\\nting antennas, receiving antennas, and subcarriers on each antenna, re spectively.For\\nthe through-wall Channel State Information (CSI) dataset, due to the com plexity\\nof through-wall environments, the original CSI data is frequently sub ject to vari-\\nous interferences, such as signal attenuation, noise disturbances, an d environmental\\nchanges.\\nAs illustrated in Fig. 1, we utilize Normalized Variance (NV) to evaluate both non-\\nthrough-wall and through-wall data.To accentuate the diﬀerences betwe en the two\\nscenarios, we apply normalized variance analysis to through-wall and non-t hrough-', metadata={'source': 'sample.pdf', 'page': 5}),\n",
       " Document(page_content='through-wall and through-wall data.To accentuate the diﬀerences betwe en the two\\nscenarios, we apply normalized variance analysis to through-wall and non-t hrough-\\nwall data within a speciﬁc action time window.Fig. 1ademonstrates the amplitude\\nvariations caused by a regular standing action, whereas Fig. 1bexhibits the amplitude\\n5', metadata={'source': 'sample.pdf', 'page': 5}),\n",
       " Document(page_content='(a)\\n (b)\\nFig. 2: Comparison of data before and after preprocessing. In the visual repre senta-\\ntion, (a) denotes the original data, while ( b) represents the data post-preprocessing.\\nThe x-axis signiﬁes the carrier index, the y-axis denotes the packe t index, and the z-\\naxis corresponds to the amplitude.\\nvariations of the same action under through-wall conditions.The distinc tion between\\nthe two is evident; the through-wall data exhibits a greater normaliz ed variance, indi-\\ncating an increase in the volatility of the channel state. The calculati on formula for\\nNormalized Variance (NV) is as follows:\\nNV=σ2\\nµ2(2)\\nhere,σ2represents the variance, calculated as:\\nσ2=1\\nN−1N∑\\ni=1(xi−µ)2(3)\\nµdenotes the sample mean, computed as:\\nµ=1\\nNN∑\\ni=1xi (4)\\nHere,xirepresents an individual sample value, and Ndenotes the number of sam-\\nples.Utilizing this formula allows for the quantiﬁcation of channel q uality variations\\nunder through-wall and non-through-wall conditions.The observation of a h igher', metadata={'source': 'sample.pdf', 'page': 6}),\n",
       " Document(page_content='ples.Utilizing this formula allows for the quantiﬁcation of channel q uality variations\\nunder through-wall and non-through-wall conditions.The observation of a h igher\\nNormalized Variance in through-wall scenarios indicates increased signal volatility,\\npotentially caused by multipath eﬀects from walls or other environmen tal factors.This\\nincrease in volatility suggests the need for appropriate data preproce ssing strategies\\n6', metadata={'source': 'sample.pdf', 'page': 6}),\n",
       " Document(page_content='to adapt to such changes. Preprocessing may include ﬁltering, den oising, or employ-\\ning more sophisticated signal processing techniques to stabilize the signal, thereby\\nenhancing the accuracy and reliability of subsequent analyses.\\n3.2 Data Preprocessing\\nInthisstudy,weemployedamedianﬁlterfornoisereductioninCh annelStateInforma-\\ntion (CSI) data.A non-linear digital ﬁltering technique, often used in signal processing\\nto reduce noise. This method preserves edges while removing noi se, by replacing each\\nentry with the median of neighboring entries.Median ﬁlters are high ly advantageous in\\nimageandsignalprocessing,particularlyeﬀectiveineliminatingsal t-and-peppernoise,\\nwhile eﬃciently preserving the edge characteristics of images.As a nonlinear ﬁltering\\ntechnique, it is less sensitive to outliers, making it particul arly eﬀective in processing\\nsignals with anomalies or noise.The fundamental equation for median ﬁlter ing is\\ny(i) = Med{x(i−k),...,x(i+k)} (5)', metadata={'source': 'sample.pdf', 'page': 7}),\n",
       " Document(page_content='signals with anomalies or noise.The fundamental equation for median ﬁlter ing is\\ny(i) = Med{x(i−k),...,x(i+k)} (5)\\nwherex(i) represents the original signal, y(i) is the signal post-ﬁltering, and kis\\nhalf the window size. In this context, we have set the window siz e of the median ﬁlter\\nto 3x3, to eﬀectively eliminate noise while preserving the edge fe atures of the signal.\\nAdditionally, considering the potential attenuation of features due to through-wall\\nsignals, we incorporated Gaussian noise augmentation to enhance the featur e repre-\\nsentation of the dataset.Adding Gaussian Noise is a process in signal proc essing where\\nGaussian noise (a statistical noise having a probability density fun ction equal to that\\nof the normal distribution) is added to a signal. This technique is com monly used in\\nalgorithmstotestrobustnessagainstnoiseortoimprovegeneralization. Theadditionof\\nGaussian noise follows the principle of z(i) =x(i)+N(µ,σ2) In this context,, N(µ,σ2)', metadata={'source': 'sample.pdf', 'page': 7}),\n",
       " Document(page_content='algorithmstotestrobustnessagainstnoiseortoimprovegeneralization. Theadditionof\\nGaussian noise follows the principle of z(i) =x(i)+N(µ,σ2) In this context,, N(µ,σ2)\\nrepresents a Gaussian distribution with a mean of µand a variance denoted by ε=\\nσ2.In our experiments, we set the mean of the Gaussian noise to 0 and the s tandard\\ndeviation to 0.1, ensuring that the noise level was moderate and did not ob scure the\\ncharacteristics of the original signal.This approach not only simulates th e uncertain-\\nties of real-world environments but also enhances the data’s represe ntational capacity\\nwhile preserving the characteristics of the original signal, making i t particularly suit-\\nable for through-wall signal processing scenarios.As demonstrated in Fi g.2, we present\\na comparison of the data before and after preprocessing.\\n4 System Architecture\\nIn this study, a deep learning-based algorithmic framework is devel oped, aimed at', metadata={'source': 'sample.pdf', 'page': 7}),\n",
       " Document(page_content='a comparison of the data before and after preprocessing.\\n4 System Architecture\\nIn this study, a deep learning-based algorithmic framework is devel oped, aimed at\\nprocessing and classifying Channel State Information (CSI) data coll ected through\\nwalls. As depicted in Fig. 4, the entire processing pipeline is segmented into sev-\\neral pivotal stages: Initially, the preprocessed through-wall CSI dat a is fed into a\\nConvolutional Neural Network (CNN) module. This module leverages its mul tiple con-\\nvolutional layers to autonomously extract spatial features from the data. T he features\\noutputted by the CNN module are then reshaped to conform to the input speciﬁca-\\ntions of subsequent modules. Subsequently, the reshaped time- series data is input into\\n7', metadata={'source': 'sample.pdf', 'page': 7}),\n",
       " Document(page_content='a Bidirectional Long Short-Term Memory (BiLSTM) module. The archite cture of the\\nBiLSTM module is meticulously designed to process time-series data, with a speciﬁc\\nfocus on capturing extended dependencies in the temporal dimens ion. Following this,\\nthe output from the BiLSTM module is conveyed to a fully connected l ayer, which is\\ntasked with mapping the temporal features onto speciﬁc categories of act ions.\\nTo augment the model’s proﬁciency in interpreting time-series data, an attention\\nmechanism has been integrated. This mechanism dynamically modulate s the model’s\\nfocus across various time steps in the sequence. By assigning atten tion weights to the\\nhidden states of the Bidirectional Long Short-Term Memory (BiLSTM) mo dule, the\\nmodel intensively processes dynamic features that are essential for the classiﬁcation\\ntask. This enhancement notably escalates the model’s accuracy in rec ognizing human\\nactivities through walls, especially in environments with complex signal patterns.', metadata={'source': 'sample.pdf', 'page': 8}),\n",
       " Document(page_content='task. This enhancement notably escalates the model’s accuracy in rec ognizing human\\nactivities through walls, especially in environments with complex signal patterns.\\nConsequently, the proposed CNN-BiLSTM framework, enriched with the attention\\nmechanism, amalgamates the strengths of spatial feature extraction and tem poral\\ndependency capture. Furthermore, it attains an in-depth comprehe nsion of time-series\\ndata via the incorporation of the attention model. This culminates in a novel and\\neﬃcacious methodology for human activity recognition in through-wall scen arios.\\n4.1 Convolutional Neural Network\\nIn our research, for the three-dimensional through-wall Channel Stat e Informa-\\ntion (CSI) dataset, we employed a two-dimensional Convolutional Neural Ne twork\\n(CNN2D) module to perform feature extraction tasks.This dataset posses ses dimen-\\nsions of 3x500x30, corresponding respectively to the number of antennas, t ime steps,', metadata={'source': 'sample.pdf', 'page': 8}),\n",
       " Document(page_content='(CNN2D) module to perform feature extraction tasks.This dataset posses ses dimen-\\nsions of 3x500x30, corresponding respectively to the number of antennas, t ime steps,\\nand amplitude information for each antenna.The design of the CNN2D module sp eciﬁ-\\ncally accounts for the unique structure of CSI data, aiming to eﬃcient ly extract spatial\\nfeatures embedded within the time-series data.\\nAs depicted in Fig. 3, the CNN2D module comprises two convolutional layers, each\\nfollowed by a Rectiﬁed Linear Unit (ReLU) and a max pooling layer.The ﬁr st con-\\nvolutional layer utilizes 3x3 kernels (with a stride of 1 and padding of 1) to process\\nsignals from diﬀerent antennas, generating feature maps containing pri mary spatial\\nfeatures.Subsequently, the ReLU activation function is applied to introduce nonlin-\\nearity, aiding in capturing more complex data patterns. Subsequent ly, a max pooling\\nlayer with 2x2 kernels and a stride of 2 is utilized to reduce the s patial dimensions of', metadata={'source': 'sample.pdf', 'page': 8}),\n",
       " Document(page_content='earity, aiding in capturing more complex data patterns. Subsequent ly, a max pooling\\nlayer with 2x2 kernels and a stride of 2 is utilized to reduce the s patial dimensions of\\nConv2D Conv2D MAX-POOL MAX-POOL\\nFig. 3: Schematic Diagram of the CNN Module.\\n8', metadata={'source': 'sample.pdf', 'page': 8}),\n",
       " Document(page_content='Fig. 4: Algorithm process framework.\\nthe feature maps while retaining essential features.This downsam pling step is aimed\\nat reducing computational load and preventing overﬁtting.The second convolutional\\nlayer further processes the features, and another ReLU activation fu nction is employed\\nto maintain nonlinearity.Then, max pooling is applied again to further reduce the\\nsize of the feature maps, facilitating higher-level feature abstract ion.The design of\\nthis CNN module takes into account the uniqueness of through-wall CSI data. With\\ncarefully selected parameters and layer structure, it ensures t hat the network eﬀec-\\ntively extracts crucial spatiotemporal features from the data, signiﬁc antly enhancing\\nthe accuracy and eﬃciency of subsequent classiﬁcation tasks.\\n4.2 BiLSTM\\nIn the architecture we propose, a Bidirectional Long Short-Term Memor y network\\n(BiLSTM) is employed following the Convolutional Neural Network (CNN) mo dule to', metadata={'source': 'sample.pdf', 'page': 9}),\n",
       " Document(page_content='4.2 BiLSTM\\nIn the architecture we propose, a Bidirectional Long Short-Term Memor y network\\n(BiLSTM) is employed following the Convolutional Neural Network (CNN) mo dule to\\neﬀectively process sequential data. As illustrated in Fig. 5,the BiLSTM enhances the\\nlearningofsequencefeaturesbycapturingthecontextualinformati onofthetimeseries\\nfrom both forward and backward directions simultaneously. In its speci ﬁc implemen-\\ntation, the BiLSTM consists of a single LSTM layer, with the input fe ature dimension\\nspeciﬁed as the reshaped output of the preceding layer, while the dimension of the\\nhidden layer is set to 64. Furthermore, we ensure that the batch siz e of the input\\nand output tensors is positioned in the ﬁrst dimension. The bidirec tional processing\\ncapability of the LSTM is also activated. This forms a comprehensive fr amework for\\n9', metadata={'source': 'sample.pdf', 'page': 9}),\n",
       " Document(page_content='analyzing time-series data. The LSTM module is renowned for its eﬃc iency in cap-\\nturing long-term dependencies in sequential data and is speciﬁcal ly tailored to handle\\nthe feature-rich outputs extracted by the preceding CNN layer. A t each time step t,\\nthe forward LSTM segment computes the hidden state− →htusing the current input xt\\nand the hidden state−−→ht−1from the previous time step, while the backward LSTM\\ncalculates← −htbased on the same input and the hidden state←−−ht+1from the subsequent\\ntime step. The output htof the bidirectional LSTM at each time step is a concate-\\nnation of the forward and backward hidden states, formulated as ht= [− →ht;← −ht]. This\\nstructure allows the model to integrate the information of the entir e input sequence\\nat each time step, thus more comprehensively capturing the long-ter m dependencies\\nin the sequence.\\n4.3 Attention mechanism\\nAdditionally, our model incorporates an attention mechanism, aimed at fur ther', metadata={'source': 'sample.pdf', 'page': 10}),\n",
       " Document(page_content='in the sequence.\\n4.3 Attention mechanism\\nAdditionally, our model incorporates an attention mechanism, aimed at fur ther\\nenhancing the identiﬁcation of key sequential information. This att ention mechanism\\nassignsaweighttoeachtimestepoutputofthebidirectionalLSTM,the rebyemphasiz-\\ning more signiﬁcant features while suppressing less relevant inf ormation. Speciﬁcally,\\nwe initially transform the BiLSTM output at each time step into a scalar using a linear\\nlayer, a step that can be viewed as scoring the importance of each time s tep. Subse-\\nquently, we apply a softmax function to normalize these scores, ensu ring that the sum\\nFig. 5: BILSTM with Integrated Attention Mechanism.\\n10', metadata={'source': 'sample.pdf', 'page': 10}),\n",
       " Document(page_content='Fig. 6: System Workﬂow.\\nof attention weights across all time steps equals 1. This process can be r epresented as:\\nat= softmax( Wattn·ht+battn) (6)\\nHere,atrepresents the attention weight for time step t, whileWattnandbattnare the\\nweight and bias of the linear layer, respectively, and htis the output of the BiLSTM\\nat time step t. Subsequently, we compute the context vector ctas the sum of the\\nweighted BiLSTM outputs:\\nc=T∑\\nt=1at·ht (7)\\nThe context vector cprovides a weighted representation of the sequence, where the\\ncontribution of each time step is determined based on its relative im portance. This\\nenables the model to utilize more reﬁned and targeted sequence feat ures in subsequent\\nfully connected layers.\\n5 Experiments And Results\\nIn this section, we detail our experimental procedures and the corr esponding results.\\n5.1 Dataset Collection\\nWe meticulously designed and constructed a data collection experim ent speciﬁcally', metadata={'source': 'sample.pdf', 'page': 11}),\n",
       " Document(page_content='In this section, we detail our experimental procedures and the corr esponding results.\\n5.1 Dataset Collection\\nWe meticulously designed and constructed a data collection experim ent speciﬁcally\\ntargeting through-wall propagation scenarios, aimed at augmenting our unders tanding\\nand simulation of wireless signal behavior in real-world environments .As depicted in\\nFig.7, the transmitter (TX) is strategically placed in an outdoor setting to emulate\\nthe reception of wireless signals within a home or oﬃce environment.C onversely, the\\nreceiver(RX)ispositionedindoors,ensuringthatthesignalsitre ceivesmustpenetrate\\nthe walls of the building.\\n11', metadata={'source': 'sample.pdf', 'page': 11}),\n",
       " Document(page_content='Fig. 7: Dataset collection scenario.\\nDuring the experimental phase, the participants engaged in a variety of pre-deﬁned\\nmotions within an indoor setting, encompassing fundamental activitie s like walking,\\nrunning, and boxing, along with a range of everyday actions. This approach w as\\ndesigned to maximize the coverage of typical human activities within the collected\\ndata. Each activity was meticulously labeled and linked with concurre nt wireless sig-\\nnal data collection. The primary objective was to furnish a comprehen sive training\\nand testing dataset for the development of advanced motion classiﬁcation al gorithms.\\nWithin the experimental setup, particular emphasis was placed on th e pathways\\nof wireless signal propagation and potential environmental obstacles. Key p arameters,\\nincluding the direct line distance between the transmitter and receiver, the material\\nproperties and thickness of walls, as well as the relative indoor and out door position-', metadata={'source': 'sample.pdf', 'page': 12}),\n",
       " Document(page_content='including the direct line distance between the transmitter and receiver, the material\\nproperties and thickness of walls, as well as the relative indoor and out door position-\\ning, were meticulously documented and analyzed. Furthermore, in or der to simulate\\nthe propagation of wireless signals in varied residential and occupational settings more\\naccurately, the positions of the subjects were varied in accordance wi th their move-\\nments to assess the impact of diverse factors on the behavior of wirele ss signals.\\nEach activity was accurately tagged and associated with the simultaneous ly collected\\nwireless signal data, with the aim of enriching the training and testi ng datasets for\\nforthcoming motion classiﬁcation algorithms.\\n12', metadata={'source': 'sample.pdf', 'page': 12}),\n",
       " Document(page_content='(a) Performance on the test set post-\\npreprocessing\\n(b) Performance on the test set with original\\ndata\\nFig. 8: Confusion Matrix for Through-Wall Activity Recognition.The horizontal ax is\\nrepresents predicted labels, while the vertical axis denotes th e true labels.\\n5.2 System Workﬂow\\nIn our study, as illustrated in Fig. 6, we employed a human activity recognition system\\nbased on Channel State Information (CSI) data.The system’s workﬂow enc ompasses\\nseveral stages: initially acquiring raw CSI data through collection de vices, followed\\nby data preprocessing involving denoising and data augmentation to en hance data\\nquality.Subsequently, the preprocessed data is fed into a dee p learning model that\\nintegrates a Convolutional Neural Network (CNN) with a Bidirectional Long Shor t-\\nTerm Memory (BiLSTM) network equipped with an attention mechanism, responsible\\nfor feature extraction and time series analysis.Ultimately, the mode l outputs a prob-', metadata={'source': 'sample.pdf', 'page': 13}),\n",
       " Document(page_content='Term Memory (BiLSTM) network equipped with an attention mechanism, responsible\\nfor feature extraction and time series analysis.Ultimately, the mode l outputs a prob-\\nability distribution for action classiﬁcation, achieving precise id entiﬁcation of human\\nactivities.\\n00.20.40.60.811.2\\nbox fall run sit squat stand walk\\nWi-SensiNet\\n CNN\\nLSTM\\nFig. 9: Accuracy of Three Models in Recognizing Various Actions.\\n13', metadata={'source': 'sample.pdf', 'page': 13}),\n",
       " Document(page_content='5.3 Experimental Results\\nIn this section, we will present a detailed exposition of the resul ts obtained from our\\nexperimental study.The experiment is designed to validate the e ﬃcacy of our pro-\\nposed model in classifying human activities.By comparing the perf ormance of the\\nmodel under diﬀerent conﬁgurations, we are able to accurately assess t he impact of\\nvarious factors on the classiﬁcation accuracy. As illustrated in Fig. 8, we conducted\\na comparative analysis of the model’s performance on both preprocessed and origi-\\nnal datasets.The results of the confusion matrix clearly demonstrate t hat the model\\ntrained on datasets subjected to noise reduction and data augmentation ex hibits supe-\\nrior classiﬁcation accuracy on the original dataset.Notably, the diagonal eleme nts,\\nrepresenting the percentage of correct classiﬁcations, are generally higher in the confu-\\nsion matrix of the preprocessed dataset compared to the original dataset. This ﬁnding', metadata={'source': 'sample.pdf', 'page': 14}),\n",
       " Document(page_content='representing the percentage of correct classiﬁcations, are generally higher in the confu-\\nsion matrix of the preprocessed dataset compared to the original dataset. This ﬁnding\\nvalidates the eﬀectiveness of our data preprocessing strategy, aﬃr ming its signiﬁcant\\nrole in enhancing the model’s generalization capability on unseen data. Fig.9presents\\nTable 1:ComparisonofwallpenetratingHARusingmachinelearningandrecogniti on\\ntechniques.\\nName Method Activity Hardware Accuracy\\nWi-SensiNet CNN-\\nBiLSTM(attention)Running, Sitting,\\nStanding, Squatting,\\nFalling, Punching,\\nWalkingWiFi devices 99%\\nTW-See[ 16] BP-network Walking, falling,\\nwaving, boxing,\\nstanding up, sitting\\ndown, emptyWiFi devices 94.46%\\nWiHACS[ 17] SVM(one wall) Sitting, standing,\\nwalking, squatting,\\nfalling, lying down,\\nstanding up after lyingWiFi devices 92%\\nRbHAR[ 18] Adaptive\\nthresholdingwalking, sitting,\\nstanding, picking up an\\nobject, drinking,fallingRadar sensors 93%', metadata={'source': 'sample.pdf', 'page': 14}),\n",
       " Document(page_content='walking, squatting,\\nfalling, lying down,\\nstanding up after lyingWiFi devices 92%\\nRbHAR[ 18] Adaptive\\nthresholdingwalking, sitting,\\nstanding, picking up an\\nobject, drinking,fallingRadar sensors 93%\\na comparative analysis of the accuracy of three distinct models in recogn izing seven\\ndiﬀerent activities.These activities include boxing, falling, running, sitting, squatting,\\nstanding, and walking.The three models are Wi-SensiNet, CNN, and LSTM re spec-\\ntively. It is observable that, in most activity recognition tasks, the accuracy of the\\nWi-SensiNet model slightly surpasses the other two models.Parti cularly in the recogni-\\ntion of falling activity, the Wi-SensiNet model demonstrates a signi ﬁcant advantage.In\\ncontrast, the performance of CNN and LSTM is relatively similar across all ac tivities,\\nthough CNN exhibits a slight edge in recognizing squatting and standing actions.This\\nchart signiﬁcantly highlights the performance disparities among diﬀe rent models in', metadata={'source': 'sample.pdf', 'page': 14}),\n",
       " Document(page_content='though CNN exhibits a slight edge in recognizing squatting and standing actions.This\\nchart signiﬁcantly highlights the performance disparities among diﬀe rent models in\\nactivity recognition tasks and provides a quantitative basis for furth er discussion and\\nanalytical research.\\n14', metadata={'source': 'sample.pdf', 'page': 14}),\n",
       " Document(page_content='Fig. 10: Accuracy performance of diﬀerent datasets.\\nAs depicted in Table 1, we conducted a comparative analysis with other literature\\nthat utilizes machine learning and recognition techniques for through -wall Human\\nActivity Recognition (HAR).These approaches include systems based on W iFi devices\\nand radar sensors, each targeting the recognition of various daily activiti es.By con-\\ntrasting these various methods, we assessed their respective pe rformances, and the\\ncomparison has illuminated the advancements made in the ﬁeld of human act ivity\\nrecognition through diﬀerent technological approaches, also oﬀering valuab le insights\\nfor our research.\\nAsdepictedinFig. 10,wepresentacomparisonoftheperformanceofthreemodels:\\nWi-SensiNet, CNN, and LSTM across diﬀerent datasets and preprocessing methods.\\nNotably, the Wi-SensiNet model consistently outperforms the other m odels across all\\ndatasets, as indicated by the higher accuracy metric. Additionally, th e preprocessing', metadata={'source': 'sample.pdf', 'page': 15}),\n",
       " Document(page_content='Notably, the Wi-SensiNet model consistently outperforms the other m odels across all\\ndatasets, as indicated by the higher accuracy metric. Additionally, th e preprocessing\\nmethod combining median ﬁltering with Gaussian noise enhancement appears to sig-\\nniﬁcantly improve model generalization, as reﬂected by the increas ed accuracy rates\\nacross datasets when this method is employed. Furthermore, the rob ustness of the Wi-\\nSensiNet model is evident from its sustained high accuracy irrespe ctive of the dataset\\npartitioning rules applied. This graph eloquently demonstrates th e superiority of the\\nWi-SensiNet model in terms of accuracy and generalization capabilities , as well as its\\nrobustness to diﬀerent data division strategies.\\n6 Conclusion\\nIn summary, this study developed an innovative human activity recogn ition system\\nbased on Channel State Information (CSI), speciﬁcally targeting activi ty detection\\nunder Non-Line-of-Sight (NLOS) conditions. The system employs state- of-the-art\\n15', metadata={'source': 'sample.pdf', 'page': 15}),\n",
       " Document(page_content='signal processing techniques, signiﬁcantly enhancing the predi ctive capability for\\nthrough-wall human activity recognition using WiFi sensing technology . The primary\\nexperimental focus was on minimizing the impact of prediction error s through walls\\non accuracy in indoor environments. Data denoising and enhancement st rategies were\\nemployed, optimizing the quality of the dataset and boosting the mod el’s adaptability\\nto new environments. Technically, the model amalgamates the spatial f eature extrac-\\ntion prowess of Convolutional Neural Networks (CNN) with the temporal analysi s\\nproﬁciency of Bidirectional Long Short-Term Memory (BiLSTM) networks , further\\naugmented by an attention mechanism. The experimental results unde rscore the high\\naccuracy of this approach in human activity recognition, demonstrating it s viability\\nin practical applications.\\nReferences\\n[1] Zhou, Z., Wu, C., Yang, Z., Liu, Y.: Sensorless sensing with wiﬁ. T singhua Science\\nand Technology 20(1), 1–6 (2015)', metadata={'source': 'sample.pdf', 'page': 16}),\n",
       " Document(page_content='in practical applications.\\nReferences\\n[1] Zhou, Z., Wu, C., Yang, Z., Liu, Y.: Sensorless sensing with wiﬁ. T singhua Science\\nand Technology 20(1), 1–6 (2015)\\n[2] Yang, J., Zou, H., Zhou, Y., Xie, L.: Learning gestures from wiﬁ: A siamese\\nrecurrent convolutional architecture. IEEE Internet of Things Jour nal6(6),\\n10763–10772 (2019)\\n[3] Li, C., Liu, M., Cao, Z.: Wihf: Enable user identiﬁed gesture recogn ition with\\nwiﬁ. In: IEEE INFOCOM 2020-IEEE Conference on Computer Communications,\\npp. 586–595 (2020). IEEE\\n[4] Ding, X., Jiang, T., Zhong, Y., Wu, S., Yang, J., Xue, W.: Improving wiﬁ -based\\nhuman activity recognition with adaptive initial state via one-shot lear ning. In:\\n2021 IEEE Wireless Communications and Networking Conference (WCNC), pp .\\n1–6 (2021). IEEE\\n[5] Zou, H., Zhou, Y., Yang, J., Jiang, H., Xie, L., Spanos, C.J.: Deepsense: D evice-\\nfreehumanactivityrecognitionviaautoencoderlong-termrecurren tconvolutional', metadata={'source': 'sample.pdf', 'page': 16}),\n",
       " Document(page_content='1–6 (2021). IEEE\\n[5] Zou, H., Zhou, Y., Yang, J., Jiang, H., Xie, L., Spanos, C.J.: Deepsense: D evice-\\nfreehumanactivityrecognitionviaautoencoderlong-termrecurren tconvolutional\\nnetwork. In: 2018 IEEE International Conference on Communications (ICC ), pp.\\n1–6 (2018). IEEE\\n[6] Palipana, S., Rojas, D., Agrawal, P., Pesch, D.: Falldeﬁ: Ubiquitous fall detection\\nusing commodity wi-ﬁ devices. Proceedings of the ACM on Interacti ve, Mobile,\\nWearable and Ubiquitous Technologies 1(4), 1–25 (2018)\\n[7] Ding, J., Wang, Y.: A wiﬁ-based smart home fall detection system usin g recur-\\nrent neural network. IEEE Transactions on Consumer Electronics 66(4), 308–317\\n(2020)\\n[8] Bahl, P., Padmanabhan, V.N.: Radar: An in-building rf-based user locat ion and\\ntrackingsystem.In:ProceedingsIEEEINFOCOM2000.ConferenceonComp uter\\nCommunications. Nineteenth Annual Joint Conference of the IEEE Comput er\\n16', metadata={'source': 'sample.pdf', 'page': 16}),\n",
       " Document(page_content='and Communications Societies (Cat. No. 00CH37064), vol. 2, pp. 775–784 (2000).\\nIeee\\n[9] Halperin, D., Hu, W., Sheth, A., Wetherall, D.: Tool release: Gathe ring 802.11 n\\ntraces with channel state information. ACM SIGCOMM computer communi ca-\\ntion review 41(1), 53–53 (2011)\\n[10] Xie, Y., Li, Z., Li, M.: Precise power delay proﬁling with commodi ty wiﬁ. In:\\nProceedings of the 21st Annual International Conference on Mobile Computi ng\\nand Networking, pp. 53–64 (2015)\\n[11] Gringoli, F., Schulz, M., Link, J., Hollick, M.: Free your csi: A c hannel state infor-\\nmation extraction platform for modern wi-ﬁ chipsets. In: Proceedin gs of the 13th\\nInternational Workshop on Wireless Network Testbeds, Experimental E valuation\\n& Characterization, pp. 21–28 (2019)\\n[12] Wang, W., Liu, A.X., Shahzad, M., Ling, K., Lu, S.: Device-free human act ivity\\nrecognition using commercial wiﬁ devices. IEEE Journal on Selected Ar eas in\\nCommunications 35(5), 1118–1131 (2017)', metadata={'source': 'sample.pdf', 'page': 17}),\n",
       " Document(page_content='recognition using commercial wiﬁ devices. IEEE Journal on Selected Ar eas in\\nCommunications 35(5), 1118–1131 (2017)\\n[13] Ma, Y., Zhou, G., Wang, S., Zhao, H., Jung, W.: Signﬁ: Sign language recogni-\\ntion using wiﬁ. Proceedings of the ACM on Interactive, Mobile, Wearab le and\\nUbiquitous Technologies 2(1), 1–21 (2018)\\n[14] Shi, Z., Zhang, J.A., Xu, R., Cheng, Q.: Deep learning networks for h uman activ-\\nity recognition with csi correlation feature extraction. In: ICC 2019-2019 IE EE\\nInternational Conference on Communications (ICC), pp. 1–6 (2019). IEEE\\n[15] Wang, J., Zhang, L., Gao, Q., Pan, M., Wang, H.: Device-free wireless se nsing\\nin complex scenarios using spatial structural information. IEEE Trans actions on\\nWireless Communications 17(4), 2432–2442 (2018)\\n[16] Wu, X., Chu, Z., Yang, P., Xiang, C., Zheng, X., Huang, W.: Tw-see: Human\\nactivity recognition through the wall with commodity wi-ﬁ devices. I EEE\\nTransactions on Vehicular Technology 68(1), 306–319 (2018)', metadata={'source': 'sample.pdf', 'page': 17}),\n",
       " Document(page_content='activity recognition through the wall with commodity wi-ﬁ devices. I EEE\\nTransactions on Vehicular Technology 68(1), 306–319 (2018)\\n[17] Chowdhury, T.Z., Leung, C., Miao, C.Y.: Wihacs: Leveraging wiﬁ for hu man\\nactivity classiﬁcation using ofdm subcarriers’ correlation. In: 2017 IE EE Global\\nConference on Signal and Information Processing (GlobalSIP), pp. 338–342\\n(2017). IEEE\\n[18] Li, Z., Le Kernec, J., Abbasi, Q., Fioranelli, F., Yang, S., Romain, O. : Radar-\\nbased human activity recognition with adaptive thresholding towards r esource\\nconstrained platforms. Scientiﬁc Reports 13(1), 3473 (2023)\\n17', metadata={'source': 'sample.pdf', 'page': 17})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "pdf_doc=splitter.split_documents(pdf_document)\n",
    "pdf_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "db=FAISS.from_documents(pdf_doc,OllamaEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing llama2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ollama()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm=Ollama(model=\"llama2\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desigining ChatPrompt Templete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(\"\"\"Answer the question only on the basis of context provided. \n",
    "                          Take provided context into consideration before providing a answer.\n",
    "                          <context>{context}</context>\n",
    "                          question:{input}\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain\n",
    "### Create Stuff Document Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002256012ACD0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retviever=db.as_retriever()\n",
    "retviever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reteriver chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "retvieval_chain=create_retrieval_chain(retviever,document_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure! Here's a summary of the provided context:\\n\\nThe article discusses the challenges of human activity recognition (HAR) in complex environments using wireless signals. The authors propose a novel approach called Wi-SensiNet, which leverages both convolutional neural networks (CNNs) and bi-directional long short-term memory (BiLSTM) networks to recognize human activities through walls. The proposed method utilizes channel state information (CSI) data to extract and utilize the most representative features within wireless signals. The authors evaluate the performance of Wi-SensiNet on a through-wall CSI dataset comprising seven common activities and achieve an average accuracy of over 99%. The results demonstrate the model's robustness and high accuracy in handling HAR tasks in complex environments, highlighting the potential of CNNs and BiLSTMs working together to enhance performance.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=retvieval_chain.invoke({\"input\":\"Give the summery of given context\"})\n",
    "response['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
